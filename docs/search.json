[
  {
    "objectID": "textanalysis.html",
    "href": "textanalysis.html",
    "title": "The Office Lines Analysis",
    "section": "",
    "text": "# load in packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\n\n# import data set\noffice_lines &lt;- read.csv(\"the-office_lines.csv\")\n\n# filter out Jim's lines when he says \"Pam\" in every season\nJim_lines &lt;- office_lines |&gt;\n  filter(Character == \"Jim\") |&gt;\n  filter(str_detect(Line, \"\\\\bPam[a-z]*\\\\b\")) |&gt;\n  group_by(Season, Episode_Number) |&gt;\n  summarize(n = n(), .groups = \"drop\") \n\n# plot of Jim's frequency of the word \"Pam\"\nggplot(Jim_lines, aes(x = Episode_Number, y = n, fill = Season)) +\n  geom_col() +\n  labs(\n    x = \"Episode Number\",\n    y = \"# of 'Pam' Occurrences\", \n    title = \"How Many Times Jim Said 'Pam' in 'The Office'\"\n  )\n\n\n\n\n\n\n\n\n“The Office,” although heavily referred to as a “comedy,” has one of the most popular romantic couples in television sitcom history: Jim and Pam. In this analysis, I counted how many times Jim said the name “Pam” / “Pamela” per episode in every season. The graph is also color-coded by season: getting a lighter shade of blue as the seasons progress. Based on the data, Jim said the name “Pam” the most on episode 4 collectively throughout every season, and this trend would decrease the longer a season went on. Ultimately, Jim referenced “Pam” in 123 episodes throughout the course of the TV show.\n\n# detect whenever somebody laughs\nlaugh_counts &lt;- office_lines |&gt;\n  filter(str_detect\n         (str_to_lower\n           (str_trim(Line)), \"\\\\[laughing\\\\]|\\\\[laughs\\\\]\")) |&gt;\n  group_by(Episode_Number, Season) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  head(n = 10)\n\n# create a table indicating laugh counts\nkable(laugh_counts, caption = \"Top 10 Laugh Counts by Season and Episode\")\n\n\nTop 10 Laugh Counts by Season and Episode\n\n\nEpisode_Number\nSeason\nn\n\n\n\n\n10\n8\n13\n\n\n18\n9\n13\n\n\n6\n1\n11\n\n\n23\n3\n11\n\n\n23\n9\n11\n\n\n5\n9\n8\n\n\n13\n7\n8\n\n\n1\n1\n7\n\n\n4\n1\n7\n\n\n16\n9\n7\n\n\n\n\n\n“The Office” is well known for their improvisations and breaking of character, leading to genuine laughter adding on to the already scripted occurrences. The above table shows a list of the Top 10 episodes in which characters laughed during their lines. This displays how Season 8, Episode 10 and Season 9, Episode 18 have the most laughter within the episode, at a total of 13 laughs. Surprisingly, these episodes actually do not parallel with what fans think are the “funniest episodes.” ScreenRant ranked Season 2, Episode 12 as the funniest episode and Collider ranked Season 4, Episode 13 the funniest."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! My name is Kandace Loualhati (Loo-uhl-haw-tee).\nI’m currently:\n\nAn undergraduate at Pomona College (class of 2027)\nDouble majoring in Politics and Cognitive Science\nMinoring in Data Science"
  },
  {
    "objectID": "SQL_proj.html",
    "href": "SQL_proj.html",
    "title": "SQL",
    "section": "",
    "text": "For this project, I am planning to recreate the Figure 1 graph from the National Library of Medicine (https://pmc.ncbi.nlm.nih.gov/articles/PMC7093226/). First, I am going to pull a dataset from SQL and read it into R to further manipulate and graph using ggplot. I plan on joining the Measurements dataset with the PI_Info dataset using their “Identifier” column and then using that new “ear_df” dataframe to select the specific information used in the original graph. From what I can see currently, the plot is a line-plot whose color is based on a combination of specific variables, so I will use that knowledge in my recreation. After the first half of the assignment is finished, I will further limit the data and create a new graph based on the “Age” variable from the Subjects dataset.\n\nlibrary(RMariaDB)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\n\nDESCRIBE Measurements;\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931\n\n\n\n\n\n\nSELECT PI_Info.Year, PI_Info.Identifier,  PI_Info.AuthorsShortList, Measurements.Instrument, Measurements.Frequency, AVG(Measurements.Absorbance) AS Absorbance, COUNT(DISTINCT SubjectNumber, Ear) AS Unique_Ears\nFROM PI_Info\nJOIN Measurements ON PI_Info.Identifier = Measurements.Identifier\nWHERE PI_Info.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Liu_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010', 'Werner_2010')\nAND Frequency BETWEEN 200 AND 8000\nGROUP BY Identifier, Instrument, Frequency\n\n\near_df &lt;- ear_df |&gt;\n  mutate(Instrument = if_else(Instrument == \"Other\", \"not commerical system\", Instrument)) |&gt;\n  mutate(legend = paste(AuthorsShortList, \"(\",Year,\")\", \"N=\", Unique_Ears,\";\", Instrument))\nggplot(ear_df, aes(x = Frequency, y = Absorbance, color = legend)) +\n  geom_line() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    title = \"Mean Absorbance from each publication in WAI database\"\n  )\n\n\n\n\n\n\n\n\nThe graph above is a recreation (for the most part) of the Figure 1 plot I intended to copy. There are one or two datasets that are different from the original study, thus a perfect representation is most likely not possible using the data provided. This depicts the relationship between the mean absorbance (scaled from 0-1) and the frequency (with a range of 200-8000 Hz) based on a combination of variables. The legend explains the different lines of the graph, based on author, year, instrument used to conduct the experiment, and the number of “unique ears.” The peak is around 3000 Hz for most of the cases in the legend.\n\nSELECT *\nFROM Subjects\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSessionTotal\nAgeFirstMeasurement\nAgeCategoryFirstMeasurement\nSex\nRace\nEthnicity\nLeftEarStatusFirstMeasurement\nRightEarStatusFirstMeasurement\nSubjectNotes\n\n\n\n\nAbur_2014\n1\n7\n20\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n3\n8\n19\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\nSession 5 not included do to acoustic leak\n\n\nAbur_2014\n4\n7\n21\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n6\n8\n21\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n7\n5\n20\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\n\n\n\n\nSELECT Measurements.Frequency, Measurements.Absorbance, Subjects.AgeFirstMeasurement AS Age\nFROM Measurements\nJOIN Subjects ON Measurements.Identifier = Subjects.Identifier\nWHERE Measurements.Frequency BETWEEN 200 and 8000\nLIMIT 100000\n\n\nggplot(age_ear_df, aes(x = Frequency, y = Absorbance, color = Age)) +\n  geom_line() +\n  scale_x_log10() +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    title = \"Mean Absorbance from each publication in WAI database (By Age)\"\n  )\n\n\n\n\n\n\n\n\nThe above graph is very similar to the one already shown. The only difference for this specific plot is that the relationship between the mean absorbance (scaled from 0-1) and frequency (with a range of 200-8000 Hz) is based on the age of participants. The ages range from 19-21, including differences in ages based on half a year (i.e. 19.5, 20.5). Unlike the previous plot, there is no obvious peak, but rather an area (between 1000-6000 Hz) for the approximate max absorbance. There appears to not be a strong relationship based on the age; however, due to the difference being only two years, this would most likely have more significant results as the ages continue to increase. Note that the graph, although mostly accurate, is limited due to the restriction of the data to 100,000 in order for my computer to cooperate. With the full data, the graph may change slightly.\nThe concepts of my original plan were able to be executed; however, there were issues and a further depth of code than I originally accounted for, that was necessary to truly be successful in my plots. First, I had to individually limit, using the WHERE function, the “ear_df” data frame to the original twelve studies in the desired plot as well as the range of the Frequency variable. After that, the line plot was quite simple to recreate, but I had to scale the Y axis using the log10 function. Then, in the second half of the assignment, I made a new graph of Mean Absorbance and Frequency based on the Age variable in the Subjects data frame; however, due to the Subjects dataframe being extremely large, my computer was not loading after my attempt to join it with Measurements. After a while, I decided to limit the frame to 100,000 units and then the data frame had no problem producing in my Environment. I then made another line plot depicting this relationship."
  },
  {
    "objectID": "employedwomen.html",
    "href": "employedwomen.html",
    "title": "Employed Women",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nemployed_gender &lt;- read.csv(\"employed_gender.csv\")\ngendered_data &lt;- employed_gender |&gt;\n  filter(year == 2012) |&gt;\n  mutate(\n    female_prop = full_time_female/total_full_time,\n    male_prop = full_time_male/total_full_time\n  )\n\nemployee_data &lt;- data.frame(\n  category = c(\"Female Workers\", \"Male Workers\"),\n  value = c(gendered_data$female_prop, gendered_data$male_prop)\n)\n\nggplot(employee_data, aes(x = \"\", y = value, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  labs(\n    x = \"\",\n    y = \"Proportion of Workers Out of Total Full Time %\",\n    title = \"Ratio of Male to Female Full-Time Workers in 2010\"\n  )\n\n\n\n\n\n\n\n\nCode from: tidytuesday/data/2019/2019-03-05/employed_gender.csv at master · rfordatascience/tidytuesday (github.com)"
  },
  {
    "objectID": "WebScraping.html",
    "href": "WebScraping.html",
    "title": "Web Scraping",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(purrr)\n\n\n# create a function that inputs a specific title for a Pomona College website and returns the facts listed on that specific URL\nweb_func &lt;- function(n) {\n  title &lt;- gsub(\" \", \"-\", n)\n  title &lt;- gsub(\"and\", \"-\", title)\n  title &lt;- gsub(\"@\", \"at\", title)\n  title &lt;- gsub(\"&\", \"-\", title)\n  title &lt;- gsub(\"-+\", \"-\", title)\n  html &lt;- paste0(\"https://www.pomona.edu/\", title)\n  page &lt;- read_html(html)\nquantity &lt;- page |&gt;\n  html_elements(\".text-7xl\") |&gt;\n  html_text()\nfacts &lt;- page |&gt;\n  html_elements(\".fact .text-xl\") |&gt;\n  html_text()\n# account for the sites that have no facts\nif (length(facts) == 0)\n  facts &lt;- \"N/A\"\nif (length(quantity) == 0)\n  quantity &lt;- \"N/A\"\n# return a tibble\ndata &lt;- tibble(\n  topic = n,\n  quantity = quantity,\n  facts = facts\n)\nreturn(data)\n}\n\n# map the different options available\ndif_titles &lt;- c(\"Admissions & Aid\", \"Academics\", \"Life @ Pomona\", \"News & Events\", \"About\", \"Alumni & Families\")\nmap(dif_titles, web_func) |&gt;\n  list_rbind()\n\n# A tibble: 22 × 3\n   topic            quantity facts                                              \n   &lt;chr&gt;            &lt;chr&gt;    &lt;chr&gt;                                              \n 1 Admissions & Aid 20%      \"of our students are the first in their family to …\n 2 Admissions & Aid 8:1      \"Student to faculty ratio on average\"              \n 3 Admissions & Aid 94%      \"live on campus all four years, creating a tight c…\n 4 Admissions & Aid 250+     \"student-run clubs and organizations to choose fro…\n 5 Academics        8:1      \"Student-to-faculty ratio\"                         \n 6 Academics        600+     \"Classes offered at Pomona each year\"              \n 7 Academics        52%      \"Students who conduct research with faculty\"       \n 8 Academics        48       \"Majors offered at Pomona College\"                 \n 9 Life @ Pomona    94%      \"of students live on campus all four years\"        \n10 Life @ Pomona    6,000+   \"students you can meet from the Claremont Colleges…\n# ℹ 12 more rows\n\n\n\n# check permission\nlibrary(robotstxt)\npaths_allowed(\"https://www.pomona.edu/academics\")\n\n[1] TRUE\n\n\n\n# create a function that takes a letter as input and returns all the U.S. government agencies that start with that letter\ngov_web_func &lt;- function(letter) {\n  if (letter == \"A\")\n    gov_html &lt;- paste0(\"https://www.usa.gov/agency-index#\", letter)\n    else\n    gov_html &lt;- paste0(\"https://www.usa.gov/agency-index/\", letter, \"#\", letter)\n  gov_page &lt;- read_html(gov_html)\n  agencies &lt;- gov_page |&gt;\n    html_elements(\"#block-views-block-federal-agencies-block-1 .usa-accordion__button\") |&gt;\n    html_text()\n  agen_list &lt;- tibble(\n    agencies = agencies |&gt;\n      str_remove(\"\\n\")\n  )\n  return(agen_list)\n}\nall_letters &lt;- setdiff(toupper(letters[1:23]), \"Q\")\nmap(all_letters, gov_web_func) |&gt;\n  list_rbind()\n\n# A tibble: 602 × 1\n   agencies                                                            \n   &lt;chr&gt;                                                               \n 1 \"AbilityOne Commission  \"                                           \n 2 \"Access Board  \"                                                    \n 3 \"Administration for Children and Families        (ACF)      \"       \n 4 \"Administration for Community Living         (ACL)      \"           \n 5 \"Administration for Native Americans        (ANA)      \"            \n 6 \"Administrative Conference of the United States        (ACUS)      \"\n 7 \"Administrative Office of the U.S. Courts  \"                        \n 8 \"Advisory Council on Historic Preservation        (ACHP)      \"     \n 9 \"Africa Command  \"                                                  \n10 \"African Development Foundation        (USADF)      \"               \n# ℹ 592 more rows\n\n\n\n# check permission\npaths_allowed(\"https://www.usa.gov/agency-index#A\")\n\n[1] TRUE"
  },
  {
    "objectID": "calfiredamage.html",
    "href": "calfiredamage.html",
    "title": "California Fire Damage",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\n calfire_damage &lt;- read.csv(\"calfire_damage.csv\")\nggplot(calfire_damage, aes(x = year, y = structures)) +\n  geom_point(color = \"orange\") +\n  labs(\n    x = \"Year\",\n    y = \"Numbers of Structures Destroyed\",\n    title = \"California Fire Damage Per Year\",\n  )\n\n\n\n\n\n\n\n\nCode from: tidytuesday/data/2018/2018-08-21/calfire_damage.csv at master · rfordatascience/tidytuesday (github.com)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! My name is Kandace Loualhati (Loo-uhl-haw-tee).\nI’m an undergraduate at Pomona College (class of 2027) who’s double majoring in Politics and Cognitive Science as well as minoring in Data Science.\nSome things to note about me:\n\nProficient in both Python and R\nBilingual (English and American Sign Language)\nServed as a researcher in Computational Chemistry and Novel Drug Design under the guidance of Roberto A. Garza-Lopez"
  },
  {
    "objectID": "Permutationtest.html",
    "href": "Permutationtest.html",
    "title": "Permutation Test",
    "section": "",
    "text": "Although the sex ratio for newborn babies seems as though it should be a random phenomenon, an article by UTSouthwestern Medical Center explains that there may actually be a genetic explanation based on the biological father. If the assumption that sex was up to chance were true, then all men who have reproduced would always have had an equal amount of X chromosomes and Y chromosomes in their sperm; however, there may be an imbalance towards Y chromosomes for biological fathers, as there is a greater likelihood for women to have baby boys instead of girls. The null hypothesis assumes that there is no inherent relationship for the likelihood of the sex of a baby; thus, if the null hypothesis can be rejected then the alternative hypothesis - that sex is not equally probable - can further be explored scientifically. \nFor my analysis, I will be using the “Births” dataset from the MosaicData package in R Studio. I plan on finding the proportions of both female and male babies, to first reveal if there is in fact an inclination towards the male sex for newborns. Afterwards, I plan on creating a function to simulate the random categorization of babies based on sex, and further using this function to find the p value and ultimately determine if the null hypothesis can successfully be rejected.\n\n# load in packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(openintro)\nlibrary(mosaicData)\n\n\n# set seed for reproducability \nset.seed(47)\n\n# import data set\nbaby_data &lt;- births\n\n# find proportion of female babies born\nfemale_prop &lt;- baby_data |&gt;\n  summarize(proportion = mean(sex_baby == \"female\")) |&gt;\n  pull()\nfemale_prop\n\n[1] 0.4533333\n\n# find proportion of male babies born\nmale_prop &lt;- baby_data |&gt;\n  summarize(proportion = mean(sex_baby == \"male\")) |&gt;\n  pull()\nmale_prop\n\n[1] 0.5466667\n\n# create a function\ntotal_babies &lt;- nrow(baby_data)\nrandom_sex &lt;- function(rep, total_babies) {\n  result = sample(c(\"female\", \"male\"), size = total_babies,\n                 replace = TRUE, prob = c(0.5, 0.5))\n  return(mean(result == \"male\"))\n}\n\n# find p value\nnum_rep &lt;- 10000\nrandom_map &lt;- map_dbl(1:num_rep, random_sex, total_babies)\np_val &lt;- sum(random_map &gt;= male_prop) / num_rep\nprint(p_val)\n\n[1] 0.1407\n\n\n\n# create a bar plot showing the difference in sex ratio \nggplot(data.frame(baby_data), aes(x = sex_baby)) +\n  geom_bar(color = \"black\", fill = \"lightpink\") +\n  labs(\n    title = \"Biological Sex Ratio for Newborn Babies\",\n    x = \"Sex\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\n\nThis is a graph depicting the natural imbalance in the biological sex ratio for newborns. There is approximately a 10% difference between females and males, for this data set alone.\n\n\n# create a new data frame for graphing\nsim_data &lt;- data.frame(simulated_male_prop = random_map)\n\n# create a histogram depicting the proportion of male births and the p-value\nggplot(sim_data, aes(x = simulated_male_prop)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"lightblue\") +\n  geom_vline(xintercept = male_prop, color = \"hotpink\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Distribution of Simulated Male Proportions\",\n       x = \"Simulated Male Proportion\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nThis is a graph showing the tendency for male proportions, when simulated many times, to arrive at the center (or around 0.5 out of the birthing population). The pink v-line, or the x-intercept, depicts the actual male proportion in birthing rates (0.5466667); however, although this line is slightly skewed to the right, the difference is not significant.\n\nUltimately, although my code did prove that there is a slight inclination for the probability that women will birth male babies instead of females, with the P-Value being 0.1407, the null hypothesis that this is due to complete randomness, cannot confidently be rejected. There is not strong enough evidence against the null hypothesis; however, if I were to repeat this analysis, I would do another permutation test using variables for both the baby’s sex and the father’s X/Y ratio, for there may be a stronger relationship there. Currently, there is not much research on this correlation, so I’d most likely need to conduct my own research or wait until somebody believes that this imbalance in the probability of sexes is significant enough to explore, despite the P-Value."
  },
  {
    "objectID": "DS02Presentation.html#web-scraping",
    "href": "DS02Presentation.html#web-scraping",
    "title": "DS02 Presentation",
    "section": "Web Scraping!",
    "text": "Web Scraping!\nGoals for this project:\n\nCreate a function that scrapes www.pomona.edu according to a specific topic the user inputs, returning all facts on that specific page\nCreate a function that scrapes www.usa.gov according to a certain letter the user inputs, returning all government agencies that start with that letter"
  },
  {
    "objectID": "DS02Presentation.html#checking-permissions",
    "href": "DS02Presentation.html#checking-permissions",
    "title": "DS02 Presentation",
    "section": "Checking permissions",
    "text": "Checking permissions\n\n# check permission\nlibrary(robotstxt)\npaths_allowed(\"https://www.pomona.edu\")\n\n[1] TRUE\n\npaths_allowed(\"https://www.usa.gov\")\n\n[1] TRUE"
  },
  {
    "objectID": "DS02Presentation.html#first-function",
    "href": "DS02Presentation.html#first-function",
    "title": "DS02 Presentation",
    "section": "First Function",
    "text": "First Function\n\n# load in packages\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(purrr)\n# create the function\nweb_func &lt;- function(n) {\n  title &lt;- gsub(\" \", \"-\", n)\n  title &lt;- gsub(\"and\", \"-\", title)\n  title &lt;- gsub(\"@\", \"at\", title)\n  title &lt;- gsub(\"&\", \"-\", title)\n  title &lt;- gsub(\"-+\", \"-\", title)\n  html &lt;- paste0(\"https://www.pomona.edu/\", title)\n  page &lt;- read_html(html)\nquantity &lt;- page |&gt;\n  html_elements(\".text-7xl\") |&gt;\n  html_text()\nfacts &lt;- page |&gt;\n  html_elements(\".fact .text-xl\") |&gt;\n  html_text()\n# account for the sites that have no facts\nif (length(facts) == 0)\n  facts &lt;- \"N/A\"\nif (length(quantity) == 0)\n  quantity &lt;- \"N/A\"\n# return a tibble\ndata &lt;- tibble(\n  topic = n,\n  quantity = quantity,\n  facts = facts\n)\nreturn(data)\n}"
  },
  {
    "objectID": "DS02Presentation.html#some-issuesexplanation",
    "href": "DS02Presentation.html#some-issuesexplanation",
    "title": "DS02 Presentation",
    "section": "Some Issues/Explanation",
    "text": "Some Issues/Explanation\n\nThe gsub() function serves as a replacement operation; in order for “n” to properly be translated into the html code, I had to remove/replace whitespaces, symbols, and the word “and”\nIn order to account for the sites that don’t have any facts, I created an if-clause for those whose lengths equal 0 to return “N/A” (i.e., News & Events)"
  },
  {
    "objectID": "DS02Presentation.html#mapping-the-func",
    "href": "DS02Presentation.html#mapping-the-func",
    "title": "DS02 Presentation",
    "section": "Mapping the Func",
    "text": "Mapping the Func\n\n# map the different options available\ndif_titles &lt;- c(\"Admissions & Aid\", \"Academics\", \"Life @ Pomona\", \"News & Events\", \"About\", \"Alumni & Families\")\nmap(dif_titles, web_func) |&gt;\n  list_rbind()\n\n# A tibble: 22 × 3\n   topic            quantity facts                                              \n   &lt;chr&gt;            &lt;chr&gt;    &lt;chr&gt;                                              \n 1 Admissions & Aid 20%      \"of our students are the first in their family to …\n 2 Admissions & Aid 8:1      \"Student to faculty ratio on average\"              \n 3 Admissions & Aid 94%      \"live on campus all four years, creating a tight c…\n 4 Admissions & Aid 250+     \"student-run clubs and organizations to choose fro…\n 5 Academics        8:1      \"Student-to-faculty ratio\"                         \n 6 Academics        600+     \"Classes offered at Pomona each year\"              \n 7 Academics        52%      \"Students who conduct research with faculty\"       \n 8 Academics        48       \"Majors offered at Pomona College\"                 \n 9 Life @ Pomona    94%      \"of students live on campus all four years\"        \n10 Life @ Pomona    6,000+   \"students you can meet from the Claremont Colleges…\n# ℹ 12 more rows"
  },
  {
    "objectID": "DS02Presentation.html#second-function",
    "href": "DS02Presentation.html#second-function",
    "title": "DS02 Presentation",
    "section": "Second Function",
    "text": "Second Function\n\n# create a function that takes a letter as input and returns all the U.S. government agencies that start with that letter\ngov_web_func &lt;- function(letter) {\n  if (letter == \"A\")\n    gov_html &lt;- paste0(\"https://www.usa.gov/agency-index#\", letter)\n    else\n    gov_html &lt;- paste0(\"https://www.usa.gov/agency-index/\", letter, \"#\", letter)\n  gov_page &lt;- read_html(gov_html)\n  agencies &lt;- gov_page |&gt;\n    html_elements(\"#block-views-block-federal-agencies-block-1 .usa-accordion__button\") |&gt;\n    html_text()\n  agen_list &lt;- tibble(\n    agencies = agencies |&gt;\n      str_remove(\"\\n\")\n  )\n  return(agen_list)\n}"
  },
  {
    "objectID": "DS02Presentation.html#some-issuesexplanation-1",
    "href": "DS02Presentation.html#some-issuesexplanation-1",
    "title": "DS02 Presentation",
    "section": "Some Issues/Explanation",
    "text": "Some Issues/Explanation\n\nThe letter “A” is the only letter that has a different HTML, so I created an if-else clause to account for that difference\nMost of the agencies ended with “\\n” so I removed that from the string\nOnly the letters A-W (except for Q) have government agencies\nAll the letters in the URL are uppercase"
  },
  {
    "objectID": "DS02Presentation.html#mapping-the-func-1",
    "href": "DS02Presentation.html#mapping-the-func-1",
    "title": "DS02 Presentation",
    "section": "Mapping the Func",
    "text": "Mapping the Func\n\nall_letters &lt;- setdiff(toupper(letters[1:23]), \"Q\")\nmap(all_letters, gov_web_func) |&gt;\n  list_rbind()\n\n# A tibble: 602 × 1\n   agencies                                                            \n   &lt;chr&gt;                                                               \n 1 \"AbilityOne Commission  \"                                           \n 2 \"Access Board  \"                                                    \n 3 \"Administration for Children and Families        (ACF)      \"       \n 4 \"Administration for Community Living         (ACL)      \"           \n 5 \"Administration for Native Americans        (ANA)      \"            \n 6 \"Administrative Conference of the United States        (ACUS)      \"\n 7 \"Administrative Office of the U.S. Courts  \"                        \n 8 \"Advisory Council on Historic Preservation        (ACHP)      \"     \n 9 \"Africa Command  \"                                                  \n10 \"African Development Foundation        (USADF)      \"               \n# ℹ 592 more rows"
  }
]