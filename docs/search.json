[
  {
    "objectID": "textanalysis.html",
    "href": "textanalysis.html",
    "title": "The Office Lines Analysis",
    "section": "",
    "text": "# load in packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\n\n# import data set\noffice_lines &lt;- read.csv(\"the-office_lines.csv\")\n\n# filter out Jim's lines when he says \"Pam\" in every season\nJim_lines &lt;- office_lines |&gt;\n  filter(Character == \"Jim\") |&gt;\n  filter(str_detect(Line, \"\\\\bPam[a-z]*\\\\b\")) |&gt;\n  group_by(Season, Episode_Number) |&gt;\n  summarize(n = n(), .groups = \"drop\") \n\n# plot of Jim's frequency of the word \"Pam\"\nggplot(Jim_lines, aes(x = Episode_Number, y = n, fill = Season)) +\n  geom_col() +\n  labs(\n    x = \"Episode Number\",\n    y = \"# of 'Pam' Occurrences\", \n    title = \"How Many Times Jim Said 'Pam' in 'The Office'\"\n  )\n\n\n\n\n\n\n\n\n“The Office,” although heavily referred to as a “comedy,” has one of the most popular romantic couples in television sitcom history: Jim and Pam. In this analysis, I counted how many times Jim said the name “Pam” / “Pamela” per episode in every season. The graph is also color-coded by season: getting a lighter shade of blue as the seasons progress. Based on the data, Jim said the name “Pam” the most on episode 4 collectively throughout every season, and this trend would decrease the longer a season went on. Ultimately, Jim referenced “Pam” in 123 episodes throughout the course of the TV show.\n\n# detect whenever somebody laughs\nlaugh_counts &lt;- office_lines |&gt;\n  filter(str_detect\n         (str_to_lower\n           (str_trim(Line)), \"\\\\[laughing\\\\]|\\\\[laughs\\\\]\")) |&gt;\n  group_by(Episode_Number, Season) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  head(n = 10)\n\n# create a table indicating laugh counts\nkable(laugh_counts, caption = \"Top 10 Laugh Counts by Season and Episode\")\n\n\nTop 10 Laugh Counts by Season and Episode\n\n\nEpisode_Number\nSeason\nn\n\n\n\n\n10\n8\n13\n\n\n18\n9\n13\n\n\n6\n1\n11\n\n\n23\n3\n11\n\n\n23\n9\n11\n\n\n5\n9\n8\n\n\n13\n7\n8\n\n\n1\n1\n7\n\n\n4\n1\n7\n\n\n16\n9\n7\n\n\n\n\n\n“The Office” is well known for their improvisations and breaking of character, leading to genuine laughter adding on to the already scripted occurrences. The above table shows a list of the Top 10 episodes in which characters laughed during their lines. This displays how Season 8, Episode 10 and Season 9, Episode 18 have the most laughter within the episode, at a total of 13 laughs. Surprisingly, these episodes actually do not parallel with what fans think are the “funniest episodes.” ScreenRant ranked Season 2, Episode 12 as the funniest episode and Collider ranked Season 4, Episode 13 the funniest."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kandace Loualhati",
    "section": "",
    "text": "Hi! My name is Kandace Loualhati (Loo-uhl-haw-tee). I’m currently a second year at Pomona College who’s intending on double majoring in Politics and Cognitive Science (with a computational concentration). I’m also a coffee addict (whoops!), an avid adventurer, and have my Seal of Biliteracy in American Sign Language :)"
  },
  {
    "objectID": "calfiredamage.html",
    "href": "calfiredamage.html",
    "title": "California Fire Damage",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\n calfire_damage &lt;- read.csv(\"calfire_damage.csv\")\nggplot(calfire_damage, aes(x = year, y = structures)) +\n  geom_point(color = \"orange\") +\n  labs(\n    x = \"Year\",\n    y = \"Numbers of Structures Destroyed\",\n    title = \"California Fire Damage Per Year\",\n  )\n\n\n\n\n\n\n\n\nCode from: tidytuesday/data/2018/2018-08-21/calfire_damage.csv at master · rfordatascience/tidytuesday (github.com)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! My name is Kandace Loualhati (Loo-uhl-haw-tee). I’m currently a second year at Pomona College who’s intending on double majoring in Politics and Cognitive Science (with a computational concentration). I’m also a coffee addict (whoops!), an avid adventurer, and have my Seal of Biliteracy in American Sign Language :)"
  },
  {
    "objectID": "employedwomen.html",
    "href": "employedwomen.html",
    "title": "Employed Women",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nemployed_gender &lt;- read.csv(\"employed_gender.csv\")\nggplot(employed_gender, aes(x = year, y = full_time_female)) +\n  geom_point(color = \"hotpink\") +\n  labs(\n    x = \"Year\",\n    y = \"% Of Women Employed Full-Time\",\n    title = \"Women Employed Full-Time Per Year\",\n  )\n\n\n\n\n\n\n\n\nCode from: tidytuesday/data/2019/2019-03-05/employed_gender.csv at master · rfordatascience/tidytuesday (github.com)"
  },
  {
    "objectID": "Permutationtest.html",
    "href": "Permutationtest.html",
    "title": "Permutation Test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\n\n\nset.seed(47)\n\n# import data set\ncancer_data &lt;- read.csv(\"wdbc.data\", header = FALSE)\n\n# find proportion of malignant tumors in women with breast cancer\nmal_prop &lt;- cancer_data |&gt;\n  summarize(proportion = mean(V2 == \"M\")) |&gt;\n  pull()\nmal_prop\n\n[1] 0.3725835\n\n# write a function to simulate women who are equally likely to have malignant and benign tumors\ntotal_women &lt;- nrow(cancer_data)\nrandom_tum &lt;- function(rep, total_women) {\n  result = sample(c(\"M\", \"B\"), size = total_women,\n                 replace = TRUE, prob = c(0.5, 0.5))\n  return(mean(result == \"M\"))\n}\n\n# repeat the function many times\nmap_dbl(1:20, random_tum, total_women)\n\n [1] 0.5465729 0.4674868 0.4956063 0.4692443 0.4833040 0.4797891 0.5166960\n [8] 0.4885764 0.5096661 0.5043937 0.4745167 0.4991213 0.5149385 0.5026362\n[15] 0.5008787 0.4938489 0.4920914 0.5289982 0.5289982 0.5026362\n\n# find p value \nnum_exper &lt;- 5000\nrandom_map &lt;- map_dbl(1:num_exper, random_tum, total_women)\nsum(random_map &gt;= mal_prop) / num_exper\n\n[1] 1"
  },
  {
    "objectID": "SQL_proj.html",
    "href": "SQL_proj.html",
    "title": "SQL",
    "section": "",
    "text": "library(RMariaDB)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\n\nDESCRIBE Measurements;\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931\n\n\n\n\n\n\ndata_set &lt;- tbl(con_wai, sql(\"\nSELECT PI_Info.Year, PI_Info.Identifier,  PI_Info.AuthorsShortList, Measurements.Instrument, Measurements.Frequency, AVG(Measurements.Absorbance) AS Absorbance, COUNT(DISTINCT SubjectNumber, Ear) AS Unique_Ears\nFROM PI_Info\nJOIN Measurements ON PI_Info.Identifier = Measurements.Identifier\nWHERE PI_Info.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Liu_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010', 'Werner_2010')\nGROUP BY Identifier, Instrument, Frequency\"))\n\near_df &lt;- collect(data_set)\n\near_df &lt;- ear_df |&gt;\n  mutate(Instrument = if_else(Instrument == \"Other\", \"not commerical system\", Instrument)) |&gt;\n  mutate(legend = paste(AuthorsShortList, \"(\",Year,\")\", \"N=\", Unique_Ears,\";\", Instrument))\n\near_df\n\n# A tibble: 7,487 × 8\n    Year Identifier AuthorsShortList Instrument Frequency Absorbance Unique_Ears\n   &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;int64&gt;\n 1  2014 Abur_2014  Abur et al.      HearID          211.     0.0785          14\n 2  2014 Abur_2014  Abur et al.      HearID          234.     0.0826          14\n 3  2014 Abur_2014  Abur et al.      HearID          258.     0.0948          14\n 4  2014 Abur_2014  Abur et al.      HearID          281.     0.103           14\n 5  2014 Abur_2014  Abur et al.      HearID          305.     0.114           14\n 6  2014 Abur_2014  Abur et al.      HearID          328.     0.122           14\n 7  2014 Abur_2014  Abur et al.      HearID          352.     0.133           14\n 8  2014 Abur_2014  Abur et al.      HearID          375      0.145           14\n 9  2014 Abur_2014  Abur et al.      HearID          398.     0.156           14\n10  2014 Abur_2014  Abur et al.      HearID          422.     0.181           14\n# ℹ 7,477 more rows\n# ℹ 1 more variable: legend &lt;chr&gt;\n\n\n\nggplot(ear_df, aes(x = Frequency, y = Absorbance, color = legend)) +\n  geom_line() +\n  scale_x_continuous(limits = c(200, 8000)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    title = \"Mean Absorbance from each publication in WAI database\"\n  )"
  },
  {
    "objectID": "Website/Permutationtest.html",
    "href": "Website/Permutationtest.html",
    "title": "Permutation Test",
    "section": "",
    "text": "Although the sex ratio for newborn babies seems as though it should be a random phenomenon, an article by UTSouthwestern Medical Center explains that there may actually be a genetic explanation based on the biological father. If the assumption that sex was up to chance were true, then all men who have reproduced would always have had an equal amount of X chromosomes and Y chromosomes in their sperm; however, there may be an imbalance towards Y chromosomes for biological fathers, as there is a greater likelihood for women to have baby boys instead of girls. The null hypothesis assumes that there is no inherent relationship for the likelihood of the sex of a baby; thus, if the null hypothesis can be rejected then the alternative hypothesis - that sex is not equally probable - can further be explored scientifically. \nFor my analysis, I will be using the “Births” dataset from the MosaicData package in R Studio. I plan on finding the proportions of both female and male babies, to first reveal if there is in fact an inclination towards the male sex for newborns. Afterwards, I plan on creating a function to simulate the random categorization of babies based on sex, and further using this function to find the p value and ultimately determine if the null hypothesis can successfully be rejected.\n\n# load in packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(openintro)\nlibrary(mosaicData)\n\n\n# set seed for reproducability \nset.seed(47)\n\n# import data set\nbaby_data &lt;- births\n\n# find proportion of female babies born\nfemale_prop &lt;- baby_data |&gt;\n  summarize(proportion = mean(sex_baby == \"female\")) |&gt;\n  pull()\nfemale_prop\n\n[1] 0.4533333\n\n# find proportion of male babies born\nmale_prop &lt;- baby_data |&gt;\n  summarize(proportion = mean(sex_baby == \"male\")) |&gt;\n  pull()\nmale_prop\n\n[1] 0.5466667\n\n# create a function\ntotal_babies &lt;- nrow(baby_data)\nrandom_sex &lt;- function(rep, total_babies) {\n  result = sample(c(\"female\", \"male\"), size = total_babies,\n                 replace = TRUE, prob = c(0.5, 0.5))\n  return(mean(result == \"male\"))\n}\n\n# find p value\nnum_rep &lt;- 10000\nrandom_map &lt;- map_dbl(1:num_rep, random_sex, total_babies)\np_val &lt;- sum(random_map &gt;= male_prop) / num_rep\nprint(p_val)\n\n[1] 0.1407\n\n\n\n# create a bar plot showing the difference in sex ratio \nggplot(data.frame(baby_data), aes(x = sex_baby)) +\n  geom_bar(color = \"black\", fill = \"lightpink\") +\n  labs(\n    title = \"Biological Sex Ratio for Newborn Babies\",\n    x = \"Sex\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\n\nThis is a graph depicting the natural imbalance in the biological sex ratio for newborns. There is approximately a 10% difference between females and males, for this data set alone.\n\n\n# create a new data frame for graphing\nsim_data &lt;- data.frame(simulated_male_prop = random_map)\n\n# create a histogram depicting the proportion of male births and the p-value\nggplot(sim_data, aes(x = simulated_male_prop)) +\n  geom_histogram(binwidth = 0.01, color = \"black\", fill = \"lightblue\") +\n  geom_vline(xintercept = male_prop, color = \"hotpink\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Distribution of Simulated Male Proportions\",\n       x = \"Simulated Male Proportion\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nThis is a graph showing the tendency for male proportions, when simulated many times, to arrive at the center (or around 0.5 out of the birthing population). The pink v-line, or the x-intercept, depicts the actual male proportion in birthing rates (0.5466667); however, although this line is slightly skewed to the right, the difference is not significant.\n\nUltimately, although my code did prove that there is a slight inclination for the probability that women will birth male babies instead of females, with the P-Value being 0.1407, the null hypothesis that this is due to complete randomness, cannot confidently be rejected. There is not strong enough evidence against the null hypothesis; however, if I were to repeat this analysis, I would do another permutation test using variables for both the baby’s sex and the father’s X/Y ratio, for there may be a stronger relationship there. Currently, there is not much research on this correlation, so I’d most likely need to conduct my own research or wait until somebody believes that this imbalance in the probability of sexes is significant enough to explore, despite the P-Value."
  },
  {
    "objectID": "Website/textanalysis.html",
    "href": "Website/textanalysis.html",
    "title": "The Office Lines Analysis",
    "section": "",
    "text": "# load in packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\n\n# import data set\noffice_lines &lt;- read.csv(\"the-office_lines.csv\")\n\n# filter out Jim's lines when he says \"Pam\" in every season\nJim_lines &lt;- office_lines |&gt;\n  filter(Character == \"Jim\") |&gt;\n  filter(str_detect(Line, \"\\\\bPam[a-z]*\\\\b\")) |&gt;\n  group_by(Season, Episode_Number) |&gt;\n  summarize(n = n(), .groups = \"drop\") \n\n# plot of Jim's frequency of the word \"Pam\"\nggplot(Jim_lines, aes(x = Episode_Number, y = n, fill = Season)) +\n  geom_col() +\n  labs(\n    x = \"Episode Number\",\n    y = \"# of 'Pam' Occurrences\", \n    title = \"How Many Times Jim Said 'Pam' in 'The Office'\"\n  )\n\n\n\n\n\n\n\n\n“The Office,” although heavily referred to as a “comedy,” has one of the most popular romantic couples in television sitcom history: Jim and Pam. In this analysis, I counted how many times Jim said the name “Pam” / “Pamela” per episode in every season. The graph is also color-coded by season: getting a lighter shade of blue as the seasons progress. Based on the data, Jim said the name “Pam” the most on episode 4 collectively throughout every season, and this trend would decrease the longer a season went on. Ultimately, Jim referenced “Pam” in 123 episodes throughout the course of the TV show.\n\n# detect whenever somebody laughs\nlaugh_counts &lt;- office_lines |&gt;\n  filter(str_detect\n         (str_to_lower\n           (str_trim(Line)), \"\\\\[laughing\\\\]|\\\\[laughs\\\\]\")) |&gt;\n  group_by(Episode_Number, Season) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  head(n = 10)\n\n# create a table indicating laugh counts\nkable(laugh_counts, caption = \"Top 10 Laugh Counts by Season and Episode\")\n\n\nTop 10 Laugh Counts by Season and Episode\n\n\nEpisode_Number\nSeason\nn\n\n\n\n\n10\n8\n13\n\n\n18\n9\n13\n\n\n6\n1\n11\n\n\n23\n3\n11\n\n\n23\n9\n11\n\n\n5\n9\n8\n\n\n13\n7\n8\n\n\n1\n1\n7\n\n\n4\n1\n7\n\n\n16\n9\n7\n\n\n\n\n\n“The Office” is well known for their improvisations and breaking of character, leading to genuine laughter adding on to the already scripted occurrences. The above table shows a list of the Top 10 episodes in which characters laughed during their lines. This displays how Season 8, Episode 10 and Season 9, Episode 18 have the most laughter within the episode, at a total of 13 laughs. Surprisingly, these episodes actually do not parallel with what fans think are the “funniest episodes.” ScreenRant ranked Season 2, Episode 12 as the funniest episode and Collider ranked Season 4, Episode 13 the funniest."
  }
]